{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyOftn0Tybn0sdZTA2jDykPG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sean-otoole/HODD/blob/main/PDTx_pipeline/PDTx_03_FineTuning_DA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#fixes a compatibility issue with the PrecollatorForGeneAndCellClassification class\n",
        "\n",
        "!pip install --upgrade transformers==4.41\n",
        "!pip install peft==0.10.0"
      ],
      "metadata": {
        "id": "6ptj23DKQbgg",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44VJt_eTgFtC",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# first mount the drive\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive to access files\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Change the working directory to the project folder in Google Drive\n",
        "os.chdir(\"/content/drive/MyDrive/HODD/\")\n",
        "\n",
        "# Install Git Large File Storage (LFS) for handling large files in Git repositories\n",
        "# !git lfs install\n",
        "\n",
        "#Clone the Geneformer repository (commented out to avoid repeated cloning)\n",
        "# !git clone https://huggingface.co/ctheodoris/Geneformer\n",
        "\n",
        "# Navigate to the Geneformer directory\n",
        "%cd Geneformer\n",
        "\n",
        "# Install Geneformer package locally\n",
        "# I found that installing Genformer first helped with a lot of the version conflict issues\n",
        "!pip install .\n",
        "\n",
        "# Install required libraries without outputting installation logs\n",
        "!pip install anndata scanpy tdigest datasets\n",
        "\n",
        "# Import necessary modules and libraries\n",
        "import numpy\n",
        "import transformers\n",
        "import sklearn\n",
        "import pickle\n",
        "import sklearn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_prefix = \"park_classifier\"\n",
        "\n",
        "data_directory = '/content/drive/MyDrive/HODD/Geneformer_parkinsons_files/'\n",
        "\n",
        "output_dir = f\"/content/drive/MyDrive/HODD/models/geneformer_finetuned_v1\"\n",
        "!mkdir $output_dir\n",
        "\n",
        "park_data_path = '/content/drive/MyDrive/HODD/Geneformer_parkinsons_files/dopamine_subset_train_tokenized.dataset/'\n",
        "\n",
        "geneformer_directory = '/content/drive/MyDrive/HODD/Geneformer/gf-12L-95M-i4096'\n"
      ],
      "metadata": {
        "id": "K1CcoN-CyWg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Fine-tune the model for cell state classification"
      ],
      "metadata": {
        "id": "6y4j1Eh7c_Cw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from geneformer import Classifier\n",
        "\n",
        "training_args = {\n",
        "    \"num_train_epochs\": 1.5,                    # Train the model for 1.5 full passes through the data\n",
        "    \"learning_rate\": 5e-5,                      # Controls how fast the model learns; smaller = slower, safer\n",
        "    \"lr_scheduler_type\": \"polynomial\",          # Gradually reduces the learning rate using a polynomial curve\n",
        "    \"warmup_steps\": 500,                        # Start with a smaller learning rate for the first 500 steps to stabilize training\n",
        "    \"weight_decay\": 0.02,                       # Helps prevent overfitting by slightly shrinking the model weights\n",
        "    \"per_device_train_batch_size\": 8,           # Number of samples the model sees at once (increase if your GPU has enough memory)\n",
        "    \"seed\": 73,                                 # Set a random seed to make results reproducible\n",
        "    \"bf16\": True,                               # Use bf16 (brain float 16) precision if your hardware supports it â€” faster & efficient\n",
        "    \"evaluation_strategy\": \"epoch\",             # Run evaluation once at the end of each training epoch\n",
        "    \"save_strategy\": \"epoch\",                   # Save the model after each epoch in case you want to go back to a previous version\n",
        "    \"load_best_model_at_end\": True,             # After training, automatically load the model that performed best on validation\n",
        "    \"metric_for_best_model\": \"eval_loss\",       # Use validation loss to decide which model is best\n",
        "    \"greater_is_better\": False                  # Lower loss means better performance, so \"greater is better\" is set to False\n",
        "}\n",
        "\n",
        "# uses the current default model\n",
        "cc = Classifier(classifier=\"cell\",\n",
        "                cell_state_dict = {\"state_key\": \"disease_state\", \"states\": \"all\"},\n",
        "                training_args=training_args,\n",
        "                max_ncells=None,\n",
        "                freeze_layers = 2,\n",
        "                num_crossval_splits = 1,\n",
        "                forward_batch_size=32,\n",
        "                nproc=16)"
      ],
      "metadata": {
        "id": "bXkilOZHyWpv"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#datsets imports for handling tokenized dataset\n",
        "from datasets import load_dataset, load_from_disk, ClassLabel\n",
        "\n",
        "#load the training data\n",
        "park_data_path = '/content/drive/MyDrive/HODD/Geneformer_parkinsons_files/dopamine_subset_train_tokenized.dataset/'\n",
        "park_data = load_from_disk(park_data_path)\n",
        "\n",
        "# Add an 'id' column that stores the original index\n",
        "park_data = park_data.add_column(\"id\", list(range(len(park_data))))\n",
        "\n",
        "# Get the unique values from the \"disease_state_numeric\" column\n",
        "classes = list(set(park_data[\"disease_state\"]))\n",
        "\n",
        "# make the disease state column a classlabel\n",
        "park_data = park_data.cast_column(\"disease_state\", ClassLabel(names=classes))  #convert the disease state numeric column to a class label\n",
        "\n",
        "# save it back to disk and rename disease state as label column\n",
        "park_data_with_id_path = '/content/drive/MyDrive/HODD/Geneformer_parkinsons_files/dopamine_subset_train_with_id_tokenized.dataset/'\n",
        "park_data = park_data.rename_column(\"disease_state\", \"label\")  # for compatibility with classifier_utils call in classifer.train_classifier\n",
        "park_data.save_to_disk(park_data_with_id_path)\n",
        "\n",
        "# get the test and eval splits\n",
        "split_data = park_data.train_test_split(test_size=0.2, seed=42, stratify_by_column=\"label\") #establish train and eval with stratification\n",
        "\n",
        "# split test and eval\n",
        "train_data = split_data['train']\n",
        "eval_data = split_data['test']\n",
        "\n",
        "# # split train into training and evaluation set\n",
        "# train_data, eval_data = split_data['train'].train_test_split(test_size=0.2, seed=42, stratify_by_column=\"label\").values()\n",
        "\n",
        "print(len(train_data))\n",
        "print(len(eval_data))\n",
        "\n",
        "# Get ids for dictionary construction\n",
        "train_ids = train_data[\"id\"]\n",
        "eval_ids = eval_data[\"id\"]\n",
        "\n",
        "# generate dictionary for validate method\n",
        "train_valid_id_split_dict = {\"attr_key\": \"id\",\n",
        "                            \"train\": train_ids,\n",
        "                            \"eval\": eval_ids}"
      ],
      "metadata": {
        "id": "AluAIm1Vkg27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "# fine tune the model\n",
        "all_metrics = cc.validate(model_directory=geneformer_directory,\n",
        "                          prepared_input_data_file = park_data_with_id_path,\n",
        "                          id_class_dict_file= '/content/drive/MyDrive/HODD/datasets/park_classifier_id_class_dict.pkl',\n",
        "                          output_directory=output_dir,\n",
        "                          output_prefix=output_prefix,\n",
        "                          split_id_dict=train_valid_id_split_dict)"
      ],
      "metadata": {
        "id": "2619aszwWgn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_metrics"
      ],
      "metadata": {
        "id": "IlfJ4Pr3zakV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Evaluate the model"
      ],
      "metadata": {
        "id": "K2F9xDTIdGBu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#add ids to the test data\n",
        "\n",
        "#load the test data\n",
        "park_data_test_path = '/content/drive/MyDrive/HODD/Geneformer_parkinsons_files/dopamine_subset_test_tokenized.dataset/'\n",
        "park_data_test = load_from_disk(park_data_test_path)\n",
        "\n",
        "# Add an 'id' column that stores the original index\n",
        "park_data_test = park_data_test.add_column(\"id\", list(range(len(park_data_test))))\n",
        "\n",
        "# Get the unique values from the \"disease_state_numeric\" column\n",
        "classes = list(set(park_data_test[\"disease_state\"]))\n",
        "\n",
        "# make the disease state column a classlabel\n",
        "park_data_test = park_data_test.cast_column(\"disease_state\", ClassLabel(names=classes))  #convert the disease state numeric column to a class label\n",
        "\n",
        "#rename the disease_state column as label\n",
        "\n",
        "park_data_test = park_data_test.rename_column(\"disease_state\", \"label\")\n",
        "\n",
        "# save it back to disk\n",
        "\n",
        "park_data_test_with_id_path = '/content/drive/MyDrive/HODD/Geneformer_parkinsons_files/dopamine_subset_test_labeled_tokenized.dataset/'\n",
        "\n",
        "park_data_test.save_to_disk(park_data_test_with_id_path)"
      ],
      "metadata": {
        "id": "d0KnomR0oglc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#saved previous model locations due to gpu memory issues\n",
        "\n",
        "current_model = '/content/drive/MyDrive/HODD/models/geneformer_finetuned_v1/250414_geneformer_cellClassifier_park_classifier/ksplit1/'\n",
        "current_dict = '/content/drive/MyDrive/HODD/datasets/park_classifier_id_class_dict.pkl'\n",
        "test_data_file = park_data_test_with_id_path\n",
        "output_dir = '/content/drive/MyDrive/HODD/models/geneformer_finetuned_v1/'\n",
        "output_prefix = \"park_classifier\""
      ],
      "metadata": {
        "id": "N_8q0Wgm3FcP"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from geneformer import Classifier\n",
        "\n",
        "cc = Classifier(classifier=\"cell\",\n",
        "                cell_state_dict = {\"state_key\": \"disease_state\", \"states\": \"all\"},\n",
        "                forward_batch_size=36,\n",
        "                nproc=16)"
      ],
      "metadata": {
        "id": "o77t4HccdL7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_metrics_test = cc.evaluate_saved_model(\n",
        "        model_directory=current_model,\n",
        "        id_class_dict_file=current_dict,\n",
        "        test_data_file = test_data_file,\n",
        "        output_directory=output_dir,\n",
        "        output_prefix=output_prefix,\n",
        "    )"
      ],
      "metadata": {
        "id": "aTmIsLqZdL4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cc.plot_conf_mat(\n",
        "        conf_mat_dict={\"Geneformer\": all_metrics_test[\"conf_matrix\"]},\n",
        "        output_directory=output_dir,\n",
        "        output_prefix=output_prefix,\n",
        ")"
      ],
      "metadata": {
        "id": "ynFJdrCwdL2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cc.plot_predictions(\n",
        "    predictions_file=f\"{output_dir}{output_prefix}_pred_dict.pkl\",\n",
        "    id_class_dict_file = current_dict,\n",
        "    title=\"disease\",\n",
        "    output_directory=output_dir,\n",
        "    output_prefix=output_prefix,\n",
        ")"
      ],
      "metadata": {
        "id": "X4QCMEqFdLza",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BrD1evqmksrg"
      }
    }
  ]
}